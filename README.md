# AIContextScraper

A powerful and reusable Python scraper framework designed for efficiently crawling documentation websites and preparing content for AI training. It features async operations, structured output formats, and intelligent content processing.

## ğŸ”‘ Key Features

- ğŸ” Recursive crawling from a single starting URL
- ğŸ§  Intelligent content extraction and structuring
- ğŸ“„ Multiple export formats (JSON, TXT, PDF)
- âš¡ Async operations for improved performance
- ğŸ”„ Automatic retry mechanism
- ğŸ“Š Token counting and chunking
- ğŸ“ Organized output structure

## ğŸ“‹ Requirements

- Python 3.8+
- Required packages listed in `requirements.txt`

## ğŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone [repository-url]
   cd AIContextScraper
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: .\venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ’» Usage

1. Run the scraper:
   ```bash
   python main.py
   ```

2. Follow the prompts:
   - Enter the documentation website URL
   - Specify a project name (or use default)
   - Choose whether to export PDFs

## ğŸ“ Output Structure

```
D:/AI_Training_Corpora/PROJECT_NAME/
â”œâ”€â”€ raw_html/           # Original HTML content
â”œâ”€â”€ json/              # Structured content with metadata
â”œâ”€â”€ txt/               # Chunked text content
â”œâ”€â”€ pdf/               # PDF exports (optional)
â”œâ”€â”€ logs/              # Execution logs
â””â”€â”€ metadata.json      # Run statistics and summary
```

## ğŸ§© JSON Structure

```json
{
  "title": "Page Title",
  "url": "https://example.com/docs/page",
  "content": "Extracted and cleaned content...",
  "tokens": 184,
  "timestamp": "2023-12-25T20:15:23Z"
}
```

## âš™ï¸ Configuration

Adjust settings in `config.py`:
- HTTP request parameters
- Crawling limits
- Content processing options
- Output formatting

## ğŸ”„ Future Enhancements

- Direct embedding export for vector databases
- Automatic content classification
- Markdown export support
- Browser-based crawling for JS-heavy sites
- Scheduled updates for documentation sites

## ğŸ“ License

MIT License - feel free to use and modify for your needs.